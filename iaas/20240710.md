# 2024-07-10

## Participants

- @belgeron
- @matusjenca2
- @gndrmnn
- @ivnucko
- @fkr
- @markus-hentsch
- @artificial-intelligence
- @lindenb1
- @maliblatt
- @horazont
- @martinmo
- @cah-patrickthiem
- @janhorstmann
- @NotTheEvilOne
- @flyersa
- @sbstnnmnn
- @berendt

## Housekeeping

- @fkr will be on vacation from the 15th on (back on the 7th of August)
- Report in this weeks community call: @artificial-intelligence
- Responsible for the minutes (writing and transfer to github): @fkr

## Agenda

### Flavor naming standard v4 - GPU flavor naming refinement (@cah-patrickthiem)

- issue: <https://github.com/SovereignCloudStack/standards/issues/366>
- PR: <https://github.com/SovereignCloudStack/standards/pull/546>
  - made a comment on why the current approach is not working in the PR
  - current approach:
    - Example: `SCS-16V-64-500s_gNa-14h`
This flavor has a pass-through GPU nVidia Ampere with 14 SMs and either high-bandwidth memory or specially high frequencies.
Looking through GPU specs you could guess it's 1/4 of an A30.
  - proposals:
    - get rid of SMs, CUs etc. and include the GPU model in the flavor name
      - only accept living GPUs with ongoing support for those flavors: <https://endoflife.date/nvidia-gpu>
        - include a list in the flavor naming standard
        - problem: currently no available list for AMD or Intel GPUs
          - maybe we can assume that their server GPUs are all not end of life yet, since they entered the market much later then Nvidia
    - not sure how to handle "h", "hh" or "hhh" for high performance
      - proposals:
        - 1\. exclude entirely
        - 2\. only mark "h" indicators in one GPU generation
          - e.g. for Nvidia Ampere generation:
            - A10 gets one "h"
            - A30 and A40 get two "hh"
            - A100 gets three "hhh"
              - SCS-16V-64-500s_GN-A100-hhh
        - 3\. mark "h" across generations
          - A10 gets no "h"
          - A30 and A40 get one "h"
          - A100 gets two "hh"
          - H100 gets three "hhh"
            - SCS-16V-64-500s_GN-A30-h
      - I have no strong opinion here, but tending to exclude it entirely
    - not sure how to handle vGPU in the flavor naming since there can be up to 7 fractions for vGPUs, meaning you can slice e.g. a Nvidia A100 into e.g. 2 parts, 6 parts or 7 parts
      - proposal:
        - SCS-16V-64-500s_7gN-A100 would mean this flavor is one part out of 7 parts in a A100
        - SCS-16V-64-500s_5gN-A100 would mean this flavor is one part out of 5 parts in a A100
        - concern: for virtualising an A100 GPU, we would need 6-7 flavors:
          - with *2gN-A100,* 3gN-A100, *4gN-A100,* 5gN-A100, *6gN-A100,* 7gN-A100
          - \_1gN-A100 could also be needed because of virtualized passthrough
    - not sure how to handle vRAM, at least there are some models, like the A100 with two configurations, there is the A100 with 40gb vRAM and also the A100 with 80 GB vRAM
      - proposals:
        - 1\. always include vRAM, also for vGPUs
          - SCS-16V-64-500s_GN-A100-40g
          - SCS-16V-64-500s_GN-A100-80g
          - SCS-16V-64-500s_2gN-A100-20g
          - SCS-16V-64-500s_3gN-A100-26,7g <-- not sure here since e.g. 1/3 of 80gb vRAM is ugly, maybe just always round off to the lesser number?
            - \--> SCS-16V-64-500s_3gN-A100-26g
          - advantage: see what you get
        - 2\. always include vRAM, don't split for vGPUs:
          - SCS-16V-64-500s_GN-A100-40g
          - SCS-16V-64-500s_GN-A100-80g
          - SCS-16V-64-500s_2gN-A100-80g
          - SCS-16V-64-500s_2gN-A100-40g
          - SCS-16V-64-500s_GN-A10-24g
        - 3\. only include vRAM in non-base-models, don't split for vGPUs:
          - SCS-16V-64-500s_GN-A100-80g
          - SCS-16V-64-500s_2gN-A100
          - SCS-16V-64-500s_2gN-A100-80g
          - advantage: less probability of error in flavor definition
  - next steps:
    - need feedback on proposals
    - make DR & update flavor naming standard to v4

### OSISM 7.1.0 (@berendt & @fkr)

- next release will be 7.1.0 on thursday
  - will contain all stable backports from upstream
    - new images for nova, glance, cinder and octavia (yeah, finally)
    - due to the large amount of updated containers @berendt decided this should be 7.1.0 instead of 7.0.6
    - will bring rook as tech preview
  - blog-post will be done by @fkr for friday

### 2024.1 Testing RCX (@fkr)

- Difference between 7.1.0 and the release candidate will be the tag to pull in OpenStack 2024.1 instead of 2023.2
- Who would be up to testing now? @berendt and @fkr propose to bring this RC out in the second week of august, since (due to the vacations in NRW and other states) it is unlikely anyone would do substantial testing now.
- @Flyersa offered to test next week, so we will actually provide a release candidate for the upcoming week
- <https://github.com/osism/issues/issues/1073>

### VPNaaS (@fkr via PS)

- how to proceed with VPNaaS
- Who has interest in driving this forward? From my (@fkr) perspective, this would like the following:
  - Epic for the integration of VPNaaS with the following stories:
    - Integration of VPNaaS in kolla-ansible upstream
    - Integration of VPNaaS in OSISM (via kolla-ansible)
    - Tests & Feedback by the stakeholders
- Uhurutec is going to add this to yaook
- VPNaaS depends on Neutron 2024.1

### PoC of node to node encryption - OVN + IPsec - demo (@ivnucko)

- working kolla-ansible deployment with Neutron agent OVN and IPsec connections between compute and control nodes
- epic [here](https://github.com/SovereignCloudStack/issues/issues/531)
- threat modeling [here](https://github.com/SovereignCloudStack/issues/issues/532)
- custom OVS - IPsec image - [PR here](https://github.com/fdobrovolny/kolla/pull/1)
- kolla-ansible [PR here](https://github.com/SovereignCloudStack/kolla-ansible/pull/4/)
- next steps:
  - open PRs for review
  - finish ADR

### Kolla Ansible TLS priority (@matusjenca2)

- 5-10 minutes
- progress of TLS in kolla-ansible is tracked [here](https://scs.sovereignit.de/nextcloud/s/G4DzznMKeJHqMBx?)
- upstream PRs [here](https://review.opendev.org/q/owner:matus.jenca@dnation.cloud+AND+project:openstack/kolla-ansible+AND+NOT+status:abandoned)
- Team Feedback needed: what takes priority?
  - TLS between ProxySQL and services using database +1
  - Backend TLS for Cloudkitty, Masakari, Mistral and Gnocchi
- Team Feedback Needed: production certificate generation/renewal documentation is missing from Kolla docs
  - In my opinion, it's better if its done by somebody more experienced in deploying Kolla in production environment
