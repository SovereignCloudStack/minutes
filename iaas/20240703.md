# 2024-07-03

## Participants

- @gtema
- @markus-hentsch
- @lindenb1
- @gndrmnn
- @sbstnnmnn
- @matofeder
- @matusjenca2
- @matfechner
- @janhorstmann
- @martinmo
- @yeoldegrove
- @garloff
- @josephineSei
- @berendt
- @NotTheEvilOne
- @kgube
- @cah-patrickthiem
- @frosty-geek
- @ivnucko

## Housekeeping

- Thanks @gtema for jumping in for @fkr last minute! :rocket: 
- Report in this weeks community call: @matofeder
- Responsible for the minutes (writing and transfer to github): @gtema

## Agenda

### Community Survey

- Nadja reminds about a Community Survey
- https://ms.scs.sovereignit.de/nextcloud/apps/forms/s/mctSbfEYEmadiJnfrLig8oir

### Questions regarding CVE-2024-32498 / OSSA-2024-001? (@fkr / @garloff)

- https://scs.community/security/2024/07/02/cve-2024-32498/
- https://security.openstack.org/ossa/OSSA-2024-001.html

### Greenfield Rook Deployments (VP03 B1 Team)

- Overview to the greenfield deployment as it has been merged into OSISM
  - [rook: initial kubernetes deployment (#881)](https://github.com/osism/ansible-collection-services/pull/1427)
  - [Initial Rook documentation (#886)](https://github.com/osism/osism.github.io/pull/588)
  - Testbed: [Enable Rook deployments (#884)](https://github.com/osism/testbed/pull/2274)
- What'll be available as Tech-Preview for R7
  - deployment of new (single) rook cluster
    - via Helm (e.g. Keyrings/CephClients need CRDs) --> based on feedback from the community, thanks @matofeder
    - highly customizable via ansible variables
  - integration into OpenStack via Keyrings (CephClients)
    - [ceph-rook - [feature] rgw Keystone and Swift integration](https://github.com/osism/issues/issues/1027) is still on open topic
- Now we need people to try this and give it a whirl
  - missing docs
  - missing features
  - ...

### Proposal to add node local storage to the OpenStack block storage service (@janhorstmann)

- Complementary to HA storage, local storage is a low latency / low cost solution
- Currently only offered through nova ephemeral storage in OpenStack
  - Bound to the lifecycle of an instance --> not cloud native
- Proposal: Make local storage available in cinder using transparent migrations based on the [device-mapper clone target](https://docs.kernel.org/admin-guide/device-mapper/dm-clone.html)
- Will be a new storage type in cinder
- Discussion:
    - Flavors with Local storage make it hard to live-migrate, this would address it
    - Switching between clone and linear DM target seems a bit nasty (couldn't we optimize it away?)
    - storage location not yet known when volume is allocated
        - would require migration on VM creation / first attachment
            - does the nova scheduler know about storage requirements to account for the needed space?
                - otherwise volume attachment fails
                    - bad for the customer - VM fails (and data is possibly lost, at least in live-migration scenario!)
                - or remain remotely attached (with bad performance)
        - can be potentially decided by configurable volume size (whether local or remote)
    - compatibility with dm-crypt?
        - probably yes
        - ensure that keys are handled when volumes are moved
    - transfer of data in dm-clone: transport security?
        - to be investigated
        - migrating crypted blocks (with dm-crypt on top of dm-clone) may still expose some data (LUKS encryption is optimized for data at rest may not be perfect for being transported)
    - Live migration
        - Nice optimization by doing lazy copying of data :-)
        - Nova scheduler still needs to check for prerequisites (can the volume be attached?) before deciding target host
    - Implementation status:
        - Currently in concept stage, prototype implementation is next

 
### Cinder Volume Backup (@markus-hentsch)

Context: Volume Backup Functionality Standard, [PR#567](https://github.com/SovereignCloudStack/standards/pull/567)

- in OpenStack, Cinder Volume Backup API is not mandatory, only offered if volume backup storage is configured
    - if not configured, API will simply not be available or reject requests
- the standard aims to make sensible choices for SCS regarding the configuration options
- main conflict: feature availability vs. backup reliability
    - a) feature availability: make the API mandatory, i.e., configure *any* volume backup storage
        - storage *may* be the same as the general volume storage; in such case backups might not truly be backups if storage fails
    - b) backup reliability: make API optional but if offered, CSP MUST use different storage backend for backups than for volumes themselves
        - improves reliability of backups in case of primary storage failure
- notes:
    - mandating both does not seem realistic: not every infrastructure can afford a dedicated volume backup storage
    - what about distributed Ceph with cross-zone replication? (would not count as separate backend but is more reliable than any arbitrary storage?)

Discussion:
- option c)
    - mandate backup feature and API availability AND make it transparent to users ("discoverability") how much additional reliability is provided
        - place of discoverability is not obvious (no place for metadata in the cinder backup API)
            - api extensions?
            - Gaia-X ~~self-descriptions~~VCs
            - new discoverability service that we work on introducing for flavors (-> public cloud SIG draft spec) [spec](https://review.opendev.org/c/openstack/publiccloud-sig/+/909387)



### Role Standard (@markus-hentsch)

Issue: [issues#396](https://github.com/SovereignCloudStack/issues/issues/396)
Standard PR: [#590](https://github.com/SovereignCloudStack/standards/pull/590)

- new findings in the issue regarding Secure RBAC (`enforce_scope`/`enforce_new_defaults`)
    - adoption rate (see [this comment](https://github.com/SovereignCloudStack/issues/issues/396#issuecomment-2197463142)) based on most common services classified as either mandatory or supported in SCS:
        - about 50% of the services default to the new options already
        - about 25% support them but still use old defaults
        - the remaining 25% do not seem to support the options
    - compatibility with Heat and roadmap (see [this comment](https://github.com/SovereignCloudStack/issues/issues/396#issuecomment-2200097660))
        - issues with Heat seem to be solved
        - 2024.2 wants to make new Secure RBAC options enabled per default for all services via oslo.policy
        - 2025.2 wants to retire the `enforce_scope` options, enforcing the new behavior
    - remaining conflict with SCS downstream *implementation* of Domain Manager
        - mutually exclusive with `enforce_scope` in Keystone (limited to Keystone)
- adoption of new Secure RBAC should already be possible except for Keystone (because of Domain Manager)
    - could get rid of service-specific special roles in Barbican and Octavia
        - resulting role set would be streamlined across all services
    - however, upstream has not concluded migration, small issues/bugs might remain
        - especially in the 25% of services that currently have unknown support state

