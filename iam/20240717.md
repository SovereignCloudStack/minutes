# 2024-07-17

## Participants

- @berendt
- @markus-hentsch
- @garloff
- @JuanPTM
- @josephineSei
- @90n20
- @gtema
- @o-otte
- @bitkeks

## Recurring items & housekeeping

- Reporting in community call: @JuanPTM
- Minutes transfer to github: @JuanPTM

## Agenda

### IAM topics (@JuanPTM)
- Import CA into Keycloak [isssue#597](https://github.com/SovereignCloudStack/issues/issues/597)
    - [Ansible-collection MR](https://github.com/osism/ansible-collection-services/pull/1480)
        - New Iteration, j2 configmap template that loads all CA certs into the initContainer
        - Additional review from @gtema wanted
        - Needs at least manual testing
            - Will be done by JuanPTM, documenting the manual steps he went through
        - Molecule tests would be nice
            - Start with keycloak service
            - Role provisions roles into k8s, ... use prepare step to deploy whatever you need in order to be able to test
            - @garloff to open issue (backlog)
        - OSISM staff can review, but does not own this component

### Domain Manager (@markus-hentsch)
- upstream spec has been merged! :rocket:
- implementation has started: https://review.opendev.org/q/topic:%22domain-manager%22
    - Keystone implementation (policies) mostly done
    - SCS standards compliance tests work
        - need to be translated into tempest test cases
    - more Tempest tests may need to be added
        - skeletons added, more tests needed

### Keycloak architecture: instances on k3s and for customer (@bitkeks)
- Currently the deployment of Keycloak is planned to be placed on the OSISM k3s. Should this instance also  contain customer data? If yes, what about security? If no, where will the customer IAM be deployed to?
- Differentiation between core-IAM for CSP site administration and open world customer federation IAM service
    - Mixing admin accounts and customer accounts in the same keycloak?
        - Better not
    - Is the system positioned correctly deep in the infrastructure when we expose it to customers for user management and federation?
        - Security isolation
        - Performance isolation
    - Do we even want to use "admin accounts" in this Keycloak?
        - Outage of instance means losing access, OpenStack, K8s
        - Federation capability not relevant for admins?
        - keycloak not meant for admins
- Same k3s cluster for ceph-rook (internal service) and keycloak (public-facing)
    - is only a question of creating load-balancers / HAproxy for them
- Goal: Separating security domains internal infra things vs. public facing services
    - Vulns in keycloak could lead to a k8s service token and then get access to other things on the same cluster (e.g. logs being exposed with information from ceph) ...
    - Can we have several k3s?
    - Different requirements for small environments (single control plane w/ 3 nodes - share clusters) and larger (highly secure) environments
        - Should be covered in blueprints
            -  But we don't have them yet
        - Small installations need to be supported
            -  Document tradeoffs (security and performance isolation)
            -  6 control nodes may be too high a requirement for small clouds
        - Large installations should have different defaults
        - Users tend to not change defaults and consider defaults to be sane and secure
- Larger discussion, way beyond k3s and keycloak:
    - Separate public-facing services (openstack API, keycloak) from internal / infrastructure services (database, ceph, ...)
    - Recommend this (and ideally create automation/mechanisms and make this separation the default for larger setups)
        - Depends on the blueprints for larger setups
- Some illustrated ideas for get improved security and safety into the keycloak setup (scoopex, added after the meeting):
  It might be possible that a few of these have already been implemented. Most of them can also be used on smaller setups.
  Scoopex did most of the items in the setup of his previous employer. 
  - Use dedicated ingresses
    - A public ingress which only provides access to api paths which are needed for federation, logon and self-service-account management.
      (this is not a problem from my experience, if the administrators of the cloud environment are located on a
       dedicated realm such as the master realm, this can be seperated in a good way)
    - A internal ingress which provides access to all needed api paths
      (used for keycloak administration, managment and apis for internal automation)
  - Configure ingresses to use a self signed tls certificate to exchange
    https traffic between ingress and keycloak.
  - Use a dedicated and restricted service account to have kube-ping (infinispan) discovery with minimized
    permissions.
  - Add worker nodes on the compute nodes (mark them with [labels](https://github.com/osism/ansible-playbooks/blob/main/playbooks/infrastructure/kubernetes-label-nodes.yml) or group the in node-groups)
    Configure the the deployment of pglcoudnative and keycloak (via bitnami chart) do use these nodes.
    This allows us to not run them on the controllers.
    Also the metallb/vip instances can be relocated to a defined subset of systems.
  - Manage ressources
    - Set relaxed resource limits for preventing keycloak/postgres instances to consume ressources
      which are needed for a more important usecase
    - Set sufficiently high resource reservations so that Keycloak can reliably perform
      its task with peak loads such as the start of the service
  - Set k8s network restrictions to ensure that all network communications is kept in the keycloak namespace
    and only allow outgoinb https upstream communication (for oauth/oidc/saml federation traffic) directly from
    the keycloak nodes.



### Security updates (@90n20)
- zuul jobs do not seem to run to completion?
    - @90n20 to send message to @o-otte
- WIP: Infra Scan pipeline documentation: [PR#9 Draft](https://github.com/SovereignCloudStack/security-infra-scan-pipeline/pull/9) 
- WIP: K8s Scan pipeline initial scripts [PR#1 Draft](https://github.com/SovereignCloudStack/security-k8s-scan-pipeline/pull/1)
    - Trivy Scans
    - Trivy Operator Deployment
    - Trivy DefectDojo Reporter integration (https://github.com/telekom-mms/trivy-dojo-report-operator)
- DefectDojo instance deployment scripts: [PR#1](https://github.com/SovereignCloudStack/defectdojo/pull/1)
- Study and evaluation ORT toolkit (https://github.com/oss-review-toolkit/ort). To sum up, it relies on many different components, which make it difficult to integrate the ecosystem on a SCS Zuul pipeline. Moreover, it is meant to be run on Jenkins CI.
