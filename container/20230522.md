# 2023-05-22
## Participants (github handles preferred)
* @o-otte
* @matfechner
* @jschoone
* @matofeder
* @batistein
* @master-caster
* @mbuechse
* @mxmxchere
* @garloff
* @joshmue
* @berendt
* @fkr
* @jnull
* @cah-hbaum
* @janiskemper

## Community call report and minutes transfer
- @o-otte

### Kurt takes over the next two meetings

## Agenda

### Updates from Registry

- https://github.com/SovereignCloudStack/k8s-cluster-api-provider/issues/417
    - 100/6h image pulls limit on docker hub
    - registry.scs.community can mirror the needed containers
        - done: do proxy-cache mirroring
        - could also mirror registry.k8s.io
            - so we don't depend on external sources to create clusters (by default)
        - also node images?
            - would make this a "air-gap" story on the container layer -> new epic (@jschoone, @garloff)
        - harbor needs to have the name of the upstream source as project, so we need to select which registries to mirror (e.g. https://registry.scs.community/docker.io/...)
    - containerd would need to consume it
        - no rewriting, so we need a mirror registry per public registry (cri-o is different here)
    - harbor HA setup exists (but not yet database)
        - fallback nicely handled by containerd
- Future: Avoid docker.io (and use quay.io instead or github or so)?
    - Tests with calico were successful
    - Probably project-dependent
    - Would be nice if our mirror (or other automation in k8s-cluster-api-provider) would hide this from end-users
- Decision: Go forward with using registry.scs.community more
    - Do we need rate-limit protection to prevent DoS? (AI research @matofeder)
    - ToDo: Define Service Level Objectives for our registry

### Repos and Epics for Cluster Stacks available

#### Repos

- https://github.com/SovereignCloudStack/cluster-stacks
- https://github.com/SovereignCloudStack/cluster-stack-operator
    - Apache 2 Licence

#### Epics

- https://github.com/SovereignCloudStack/issues/issues/321
- https://github.com/SovereignCloudStack/issues/issues/326


## Standards

- Standardize k8s networking policies (CNI) [issues/#211](https://github.com/SovereignCloudStack/issues/issues/211)
    - Do k8s networking policies cover everything that most DevOps teams need to develop and run their apps on k8s clusters?
        - If so, we would standardize on those and the implementation choice (calico vs cilium) is indeed just an implementation detail
            - Data point from gonicus: Sufficient in some projects, not in others (hardcoding IP addresses needed in k8s netPols)
            - More research needed
        - If not, the choice becomes a lot more critical and we need to take sides
            - This might prevent partners to be SCS standards compliant
- Define criteria to take the decision on the default
    - Performance, Observability, Features, Avoiding kube-proxy, ...
    - https://platform9.com/wp-content/uploads/2021/06/benchmark.png (Up-to-date? Neutral?)
