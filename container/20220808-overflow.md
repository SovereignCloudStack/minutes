# 2022-08-08 Overflow slow

## Participants - use of github handle is preferred
* @garloff
* @matfechner
* @batistein
* @janiskemper
* @joshmue
* @burkhard

## Agenda
Continue the discussion from the container team meeting (2022-08-08):
KaaS offering: The assumption is that the provider offers a k8s (kube-apiserver) style interface (where in the reference implementation a management server with CAPI/SCS operator is running), accepting custom resources for controlling customer workload clusters.
1. Challenge: If cloud providers offer a k8s (kube-apiserver) endpoint for cluster management, there are a few challenges: If the endpoint is backed by a k8s cluster, it needs serious multi-tenancy features (authentication+authorization concepts, strong isolation beyond just namespaces, ...).
2. Alternative challenge: The cloud provider could run a management cluster per customer. Trouble is the overhead then: Running a 3c+1w/+0w cluster per customer. (Could we just run the single-node kind cluster an defer the clusterctl move when this is really used? Move to first workload cluster? Move to another cluster or back to  kind cluster if that first workload cluster gets deleted?)
3. Discussion: If DevOps teams want to control their own cluster using a k8s style API, aren't they capable and willing to run the management cluster anyway, deployable by a single click/API call? If the SCS operator supposedly takes out most pain from operating workload clusters, it should also take out the pain from running the management cluster, no?

Janis point:
SCS-API only for self-service for IaaS users (and internally for providers).
KaaS-only users may not care as much about API? (But do they care about standard SCS defined cluster properties / behavior?)

Andrej:
Need provider specific interaction for connecting to provider-specific networks or PaaS servcies anyway
API endpoint may not be backed by k8s cluster?
kubectl like interface without having a kube-apiserver as endpoint? Making API endpoing creation easier.
mgmt cluster cost (infra ~100EUR/m + people for ops) can easily become prohibitive, unless many clusters are created and managed.

Joshua:
Managed kubernetes backed with CAPI and without CAPI
Who has responsibility for keeping it working?

Requirements:
    * Reference implementation allows std infra to be transformed into a full KaaS offering
    * Recreating same cluster at different provider needs to be possible (migration use case)
    * API needs to be versioned

Standard parameters / CRDs can not work for existing KaaS offerings?
- Minimal set of parameters from current gridscale should not limit us (as this will and should grow)
- Minimal template (clusterstack) may be the only one that gridscale supports (with minimal set of parameters), like Google Autopilot (https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview?hl=en)

teuto.net setup:
CAPI mgmt cluster running at provider (not exposed publicly), API in front of it that is exposed to customers
Only power users can request their own private CAPI mgmt cluster
One challenge is status/error/... reporting (->prometheus)

Wanted:
Synchronous --wait/--poll option (returning status, logs, kubeconfig, ...)

Suggested:
SCS Operator could collect status, report phases, ... to allow for status reporting

=> Bringing it together

```
PROVIDER                                                         |       CUSTOMER
managed KaaS model:
A1 [ CAPI/SCS Operator ]  <->  [ REST API ]  <->  cluster-values.yaml (standardized!)
A2 [  Provider specific solution .......................  ] <->  cluster-values.yaml

Self-Management model:                                           |
B  [ SCS KaaS conforming IaaS + drivers ]  <->  [ CAPI/SCS Operator ] (references cluster stacks, ..., and can use <-> cluster-values.yaml to render CRDs)
```

cluster-values.yaml are the parameters per cluster-stack. (Few parameters for simple cluster, more for more flexible clusters ...).
Cluster properties need to be defined and standardized! Conformance tests needed.

Remaining discussion:
    * REST API chosen because kube-apiserver backed interface is too expensive
    * Can't we somehow make k8s APIs cheap enough (multi-tenant or tiny mgmt clusters?) to provide a k8s interface? kcp / kata / .... ? logical/virtual clusters? 
    => Medium-term goal remains to have k8s CRD style interface, as soon as we can create an efficient way like https://crossplane.io/

Crossplane: translates (provider-specifc) REST APIs into declarative k8s-style CRDs
- provider specific
- may be hard to overcome (e.g. because of  network handling)

    * REST API for platform services? k8s like interface better?
	    * SCS-PaaS-Operator("extendedCCM") deployed  into created workload cluster to manage PaaS?

Building it: node images, cluster-stack templates, provider specific features, lifecycle (CAPI), operator: manages things

Cluster Stacks should be pluggable (and come from github via provider specific repos ...). reference implementation in SCS, could be forked by providers or just use overlays (kustomize), .... later: optional generate packer configs for node image creation. (First step: test expected properties of images -- minimal set of requirements, software is defined.) - plugin; avoid image explosion by requiring cloud-init support

Self-description: Per-cluster-stack: behavior, parameter space - plus REST API

User journey: How does user interact with provider?
B: Bootstrap CAP/SCS operator, define CRDs, create cluster, clusterctl move CAPI into cluster, ....
A: 
