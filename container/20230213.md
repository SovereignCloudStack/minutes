# 2023-02-13

## Participants (github handles preferred)
* @master-caster
* @maxwolfs
* @batistein
* @jschoone
* @chess-knight
* @o-otte
* @mpilka
* @matofeder
* @mxmxchere
* @fkr
* @joshmue
* @ajfriesen
* @itrich

## Community call report and minutes transfer
  @jschoone

## Agenda
Sprint review & planning, see Kanban board @ https://github.com/orgs/SovereignCloudStack/projects/6/views/7

### Standardization work

#### Ingress & Loadbalancing (issues/#227)
* issues/#251: OVN provider loadbalancer does result in client IPs being visible (DSR-like, L3 LB)
  - https://github.com/SovereignCloudStack/issues/issues/268#issuecomment-1427023428:
    health-monitor available, detects ERROR operating_status (and thus a degraded pool status), but does not seem to take ERROR'ed members out -> IaaS team
  - Expect this to be resolvable, so we'll have what we want on SCS IaaS providers with OVN
* issues/#250: Proxy protocol can be used, setting hostname dns suffix may resolve local connection issues:
  https://github.com/SovereignCloudStack/k8s-cluster-api-provider/pull/323
  - This requires custom annotations and thus only works for provider-created ingress out-of-the-box
  - User deployments (with standard deployment files/helm charts using externalTrafficPolicy: Local without using custom annotations) will either (issues/#312)
    * (a) fail to respond to most requests (in case we don't enable LB health-mon by default)
      - preferrable, as user will more likely notice failure and address BOTH aspects (health-mon AND proxy-proto)
    * (b) succeed in responding reliably but don't deliver client IPs (in case we enable health-mon by default)
  - Should be documented
  - Short ADR on this decision: standards/#169
    * Finalize it (@joshmue, others to contribute)

#### Storage
* standards/#198: Default storage class (ADR scs-0211): Stabilize?
  - Hooray! (@garloff to merge PR)
* issues/#214: Proceeding with additional storage classes:
  - Performance (IOPS, combined with bandwidth?)
    * Local storage w/ low latency w/o replication
  - Encryption (with user keys?)
  - RWX!

* Side-discussion:
  - etcd backed by ceph storage (SSD-only) works just fine in gridscale
  - no etcd replication enabled there, single-node etcd and kube-api (rely on ceph to keep data safe, bring up new etcd/kube-api if master fails, also have very recent snapshots in case the filesystem ends up corrupted)
  - OpenShift might not like the single node control plane ...

* Importance of local low latency storage?
  - Bare Metal has it ...
  - Cloud providers and managed k8s providers not so often

* RWX is desired a lot
  - workaround: provide it yourself (samba/NFS/....)
  - owncloud infinite scale
  - list of more apps wanting/requiring it from @batistein: ...
  - good goal for R5!

#### Registry
* issues/#263: Investigation status?
  * standards/#212: ADR Draft by dNation
  * very nice progress, please review ADR!

### Reference Implementation work
* k8s-cluster-api-provider/#324: k8s.gcr.io -> registry.k8s.io pain: Please review!
  - will also backport this to R3 (v4.x)
* k8s-cluster-api-provider/#323:
  - hostname setting for proxy proto, see above
* k8s-cluster-api-provider/#322:
  - upstream deployment.yaml referencing old upstream image
  - report and patch?
