# 2024-03-21

## :family: Participants (github handles preferred)

* @artificial-intelligence
* @martinmo
* @matofeder
* @michal-gubricky 
* @joshuai96
* @joshmue
* @o-otte
* @chess-knight
* @cah-hbaum
* @garloff
* @mxmxchere
* @DEiselt

## :telephone: Community call and minutes transfer
* Who is presenting in weekly community call and transforming the minutes into GitHub?
     * Minutes-transfer: @matofeder
     * Report in Community-Call: @matofeder

## :notebook: Agenda

### Node distribution standard extensions (@cah-hbaum 10min)

- reference: issue [issues/494](https://github.com/SovereignCloudStack/standards/issues/494), PR [standards/524](https://github.com/SovereignCloudStack/standards/pull/524)
- in order to (a) improve transparency and (b) make testing possible, we now REQUIRE certain node labels:
    - `topology.kubernetes.io/region` as defined in the [k8s docs](https://kubernetes.io/docs/reference/labels-annotations-taints/#topologykubernetesiozone)
    - `topology.kubernetes.io/zone` as defined in the [k8s docs](https://kubernetes.io/docs/reference/labels-annotations-taints/#topologykubernetesioregion)
    - `topology.scs.community/host-id` (note: not necessarily the hostname, but some identifier _unique to the physical host_)
- question: can we update v1?
    - strictly speaking, this change calls for a new major version of the standard
    - less strictly, more pragmatically:
        - v1 of the standard is really new and most likely _hasn't been adopted by anybody_
        - a new major version _clutters the space_
        - future people might wonder _unnecessarily_ what v1 was ever good for
    - shall we (a) update v1 or (b) create a v2?
- question: do these labels work for you people?
    - team container is OK with the proposed labels
        - already implemented in KaaSv1
- next steps:
    - @garloff: bring this topic/question of v1 vs v2 to the SIG Standardization meeting

### Update on CSCTL plugin OpenStack (@michal-gubricky ~3min)

- First working iteration of CSCTL plugin OpenStack
  - build plugin binary from this [draft PR](https://github.com/SovereignCloudStack/csctl/pull/92) if you want to test it 
  - more improvements are on the way

### Migration path from v1 to v2 (@chess-knight ~3min)

- Upgrade KaaS v1 from R5 to R6 -- Done
- Upgrade [KaaS v1 to v2](https://github.com/SovereignCloudStack/issues/issues/544)
    - Cluster Stacks [PR#36](https://github.com/SovereignCloudStack/cluster-stacks/pull/36) - DONE
    - Support diskless flavors during migration - DONE
    - Migration [guide](https://github.com/SovereignCloudStack/issues/issues/544#issuecomment-1999746262) - call for testing
        - Let's do internal testing first (would be nice to find tester from different company than dNation) and then reach out to AOV (and stackXperts for their partners)
            - B1 team will take care of the testing 

### End-to-end testing (Zuul) for KaaS is dysfunctional because of high latency in gx-scs (@matofeder ~5min)

- KaaS V1 e2e Zuul builds [failed](https://zuul.scs.community/t/SCS/builds?project=SovereignCloudStack%2Fk8s-cluster-api-provider&skip=0) due to high latency
- Observer and Harbor k8s clusters (both gx-scs) are in troubles as well
- Related metrics dashboards (observed from Harbor cluster, from last 7days, source https://monitoring.scs.community/):
    - Control plane nodes - I/O time (ms):
    ![](https://input.scs.community/uploads/1bc69fef-1a0c-4b0f-b25a-fc29eeea84f2.png)
    - Etcd cluster - Total leader elections (per day)
    ![](https://input.scs.community/uploads/112fc261-db7e-4d55-8d29-14c923bfdd5e.png)
    - Etcd cluster - Disk WAL fsync duration (seconds)
    ![](https://input.scs.community/uploads/640a4c7d-7c39-42ff-8820-a797c7eff48b.png)
    - Etcd cluster - Disk backend commit duration (seconds)
    ![](https://input.scs.community/uploads/c8acffe6-88eb-4ee7-86c5-bb9eb7cbde41.png)

    - Three theories on the cause in gx-scs:
        1. network cleanup since Feb 14 (ports disappear just after :30 every hour) in gx-scs, offender not yet found by PS team (they are aware since weeks)
        2. update of gx-scs to R6 (on Mar 14) was not good, known issues with octavia (but not cinder nor ceph)
        3. higher load on ceph (which also backs "local" root volume for flavors with disks on plus environments)

    - The issue will be resolved with the "s" flavors: SCS-2V-4-20s and SCS-4V-16-100s that will be available "really soon" (based on info from Ralf (PS))
    - What can we do in the meantime?
        - AI @dnation: We should reach out to the PS team and report our observation
        - AI @dnation: Will try to workaround our current issue as follows:
        - Options:
            - 1. Increase (even more) etcd heartbeat interval and election timeout, [current etcd setup](https://github.com/SovereignCloudStack/k8s-cluster-api-provider/blob/main/terraform/files/template/cluster-template.yaml#L109)
                - what are the side effects?
                - !this should be **temporary** solution!
            - 2. Having a separate FS for the etcd
            - 3. Having a separate DISK for the etcd
            

### Tighter coupling between cluster-stacks GitHub Releases and repo state (@mxmxchere, if time left)

- Refer to [#32](https://github.com/SovereignCloudStack/cluster-stacks/issues/32)
    - Cluster stack release should aim the certain point in the main branch (e.g. TAG)
    - Goal: Released software (released assets) should be traceable back to the sources (state in github repositorie**s**)
        - Reproducable builds
    - @janis: csctl should be used for the releasing the cluster-stacks; but csctl does not TAG the main branch
    - Ideas:
        - Support tagging from csctl
        - CI integration: Action to build assets from PRs
        - alpha/beta channels for sharing things in development
